{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dagmaros27/AIMS_Notebooks/blob/main/CUDA_Practical_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CUDA Programming on NVIDIA GPUs**\n",
        "\n",
        "# **Practical 3**\n",
        "\n",
        "Again make sure the correct Runtime is being used, by clicking on the Runtime option at the top, then \"Change runtime type\", and selecting an appropriate GPU such as the T4.\n",
        "\n",
        "Then verify with the instruction below the details of the GPU which is available to you.  "
      ],
      "metadata": {
        "id": "i1JlUA_e44zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uboEpcMD4xYA",
        "outputId": "ebf092e5-4bed-40e0-a040-c775f2e3ea01"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan 24 07:19:24 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "First we upload two header files from the course webpage."
      ],
      "metadata": {
        "id": "nlO6dHwW7gRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
        "!wget https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv1nyjTmTmr7",
        "outputId": "0e84a37b-43ba-4293-c11f-16646969acfc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-24 07:19:28--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_cuda.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:201::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27832 (27K) [text/x-chdr]\n",
            "Saving to: ‘helper_cuda.h’\n",
            "\n",
            "helper_cuda.h       100%[===================>]  27.18K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2026-01-24 07:19:29 (200 KB/s) - ‘helper_cuda.h’ saved [27832/27832]\n",
            "\n",
            "--2026-01-24 07:19:29--  https://people.maths.ox.ac.uk/gilesm/cuda/headers/helper_string.h\n",
            "Resolving people.maths.ox.ac.uk (people.maths.ox.ac.uk)... 129.67.184.129, 2001:630:441:201::8143:b881\n",
            "Connecting to people.maths.ox.ac.uk (people.maths.ox.ac.uk)|129.67.184.129|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14875 (15K) [text/x-chdr]\n",
            "Saving to: ‘helper_string.h’\n",
            "\n",
            "helper_string.h     100%[===================>]  14.53K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2026-01-24 07:19:29 (363 KB/s) - ‘helper_string.h’ saved [14875/14875]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "The next step is to create the file laplace3d.cu which includes within it a reference C++ routine against which the CUDA results are compared."
      ],
      "metadata": {
        "id": "RD6IjBwY2Ltm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  j    = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, REPEAT=20,\n",
        "            BLOCK_X, BLOCK_Y, bx, by, i, j, k;\n",
        "  float    *h_u1, *h_u2, *h_foo,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "  //cudaEventRecord(start);\n",
        "  //for (i=0; i<REPEAT; i++) {\n",
        "  //  Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "  //  h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "  //}\n",
        "\n",
        "  //cudaEventRecord(stop);\n",
        "  //cudaEventSynchronize(stop);\n",
        "  //cudaEventElapsedTime(&milli, start, stop);\n",
        "  //printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  BLOCK_X = 64; // number of threads\n",
        "  BLOCK_Y = 16; // in each direction\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X; // number of blocks\n",
        "  by = 1 + (NY-1)/BLOCK_Y; // in each direction\n",
        "\n",
        "  dim3 dimGrid(bx,by);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y);\n",
        "\n",
        "  // Execute GPU kernel\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "\n",
        "  for (i=0; i<REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "  }\n",
        "\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Block dimensions: %d x %d \\n\", BLOCK_X,BLOCK_Y);\n",
        "  printf(\"%dx GPU_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "id": "r-4zYq9zLYs3",
        "outputId": "e9c4356c-c7fc-456e-e28c-9c0f0d44280b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "We can now compile and run the executable.\n"
      ],
      "metadata": {
        "id": "yds03ug532rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d.cu -o laplace3d -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFHWm4Dd3_hw",
        "outputId": "1f6d2cea-ea86-450a-9bae-001d7f96c301"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 64 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7jX9dSAaLj0",
        "outputId": "2b9a35c4-ee8f-4def-82b5-35443bcb24ec"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 968.0 (ms) \n",
            "\n",
            "Block dimensions: 64 x 16 \n",
            "20x GPU_laplace3d: 1210.7 (ms) \n",
            "\n",
            "Copy u2 to host: 2811.4 (ms) \n",
            "\n",
            "rms error = 0.066320 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Grid dimensions: 1024 x 1024 x 1024\n",
        "\n",
        "GPU Device 0: \"Turing\" with compute capability 7.5\n",
        "\n",
        "Copy u1 to device: 938.8 (ms)\n",
        "\n",
        "Block  2 x  2  ->  5071.906 ms\n",
        "Block  2 x  4  ->  5656.572 ms\n",
        "Block  2 x  8  ->  10098.975 ms\n",
        "Block  2 x 16  ->  18532.633 ms\n",
        "Block  2 x 24  ->  22519.248 ms\n",
        "Block  2 x 32  ->  23792.822 ms\n",
        "Block  2 x 64  ->  25030.516 ms\n",
        "Block  4 x  2  ->  5273.936 ms\n",
        "Block  4 x  4  ->  6782.370 ms\n",
        "Block  4 x  8  ->  7705.290 ms\n",
        "Block  4 x 16  ->  11683.622 ms\n",
        "Block  4 x 24  ->  11806.559 ms\n",
        "Block  4 x 32  ->  11969.221 ms\n",
        "Block  4 x 64  ->  12230.748 ms\n",
        "Block  8 x  2  ->  2203.408 ms\n",
        "Block  8 x  4  ->  2161.137 ms\n",
        "Block  8 x  8  ->  3006.282 ms\n",
        "Block  8 x 16  ->  3431.023 ms\n",
        "Block  8 x 24  ->  3469.136 ms\n",
        "Block  8 x 32  ->  3829.409 ms\n",
        "Block  8 x 64  ->  4184.480 ms\n",
        "Block 16 x  2  ->  1661.684 ms\n",
        "Block 16 x  4  ->  1852.686 ms\n",
        "Block 16 x  8  ->  1842.868 ms\n",
        "Block 16 x 16  ->  1930.509 ms\n",
        "Block 16 x 24  ->  1839.395 ms\n",
        "Block 16 x 32  ->  2090.338 ms\n",
        "Block 16 x 64  ->  2002.745 ms\n",
        "Block 24 x  2  ->  2131.153 ms\n",
        "Block 24 x  4  ->  1809.894 ms\n",
        "Block 24 x  8  ->  1870.719 ms\n",
        "Block 24 x 16  ->  1694.615 ms\n",
        "Block 24 x 24  ->  1728.848 ms\n",
        "Block 24 x 32  ->  1756.730 ms\n",
        "Block 32 x  2  ->  1465.997 ms\n",
        "Block 32 x  4  ->  1280.623 ms\n",
        "Block 32 x  8  ->  1237.430 ms\n",
        "Block 32 x 16  ->  1243.163 ms\n",
        "Block 32 x 24  ->  1272.825 ms\n",
        "Block 32 x 32  ->  1270.032 ms\n",
        "Block 64 x  2  ->  1483.745 ms\n",
        "Block 64 x  4  ->  1325.004 ms\n",
        "Block 64 x  8  ->  1231.041 ms\n",
        "Block 64 x 16  ->  1191.235 ms\n",
        "\n",
        "==== BEST CONFIGURATION ====\n",
        "Block: 64 x 16   Time: 1191.235 ms\n",
        "Copy u2 to host: 2908.7 (ms)\n",
        "\n",
        "rms error = 0.125000\n"
      ],
      "metadata": {
        "id": "WIxxIIL7HHM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "By going back to the previous code block you can modify the code to complete the initial Practical 3 exercises. Remember to first make your own copy of the notebook so that you are able to edit it.\n",
        "\n",
        "For students doing this as an assignment to be assessed, you should again add your name to the title of the notebook (as in \"Practical 3 -- Mike Giles.ipynb\"), make it shared (see the Share option in the top-right corner) and provide the shared link as the submission mechanism.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "For the later parts of Practical 3, the instructions below create, compile and execute a second version of the code in which each CUDA thread computes the value for just one 3D grid point."
      ],
      "metadata": {
        "id": "ncymVLmd4L82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_new.cu\n",
        "\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  j    = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "  k    = threadIdx.z + blockIdx.z*blockDim.z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, REPEAT=1,\n",
        "            BLOCK_X, BLOCK_Y, BLOCK_Z,bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "//   cudaEventRecord(start);\n",
        "//   for (i=0; i<REPEAT; i++) {\n",
        "//     Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "//     h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "//   }\n",
        "\n",
        "//   cudaEventRecord(stop);\n",
        "//   cudaEventSynchronize(stop);\n",
        "//   cudaEventElapsedTime(&milli, start, stop);\n",
        "//   printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  BLOCK_X =32; // number of threads\n",
        "  BLOCK_Y = 2; // in each direction\n",
        "  BLOCK_Z = 8; // of 3D thread block\n",
        "\n",
        "  bx = 1 + (NX-1)/BLOCK_X; // number of blocks\n",
        "  by = 1 + (NY-1)/BLOCK_Y; // in each direction\n",
        "  bz = 1 + (NZ-1)/BLOCK_Z; // of 3D grid of blocks\n",
        "\n",
        "  dim3 dimGrid(bx,by,bz);\n",
        "  dim3 dimBlock(BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "\n",
        "// Execute GPU kernel\n",
        "\n",
        "cudaEventRecord(start);\n",
        "\n",
        "for (i=0; i<REPEAT; i++) {\n",
        "  GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "  getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "  d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;   // swap d_u1 and d_u2\n",
        "}\n",
        "\n",
        "cudaEventRecord(stop);\n",
        "cudaEventSynchronize(stop);\n",
        "cudaEventElapsedTime(&milli, start, stop);\n",
        "printf(\"Block dimensions: %d x %d x %d\\n\", BLOCK_X,BLOCK_Y,BLOCK_Z);\n",
        "printf(\"%dx GPU_laplace3d_new: %.1f (ms) \\n\", REPEAT, milli);\n",
        "\n",
        "// Calculate bandwidth per iteration\n",
        "float time_per_iter = milli / (float)REPEAT / 1000.0f; // convert to seconds\n",
        "float bytes_per_iter = 2.0f * (float)bytes; // read d_u1 + write d_u2\n",
        "float gb_per_iter = bytes_per_iter / 1e9f; // convert to GB\n",
        "float effective_bw = gb_per_iter / time_per_iter;\n",
        "\n",
        "printf(\"\\nBandwidth Analysis:\\n\");\n",
        "printf(\"Time per iteration: %.3f ms\\n\", milli / (float)REPEAT);\n",
        "printf(\"Data per iteration: %.3f GB\\n\", gb_per_iter);\n",
        "printf(\"Effective Bandwidth: %.2f GB/s\\n\\n\", effective_bw);\n",
        "\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "id": "RPDzsoUJLh6B",
        "outputId": "eb469614-ce06-422c-fa16-feffb9eeadea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_new.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc laplace3d_new.cu -o laplace3d_new -I. -lineinfo -arch=sm_70 --ptxas-options=-v --use_fast_math -lcudart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGXiohVT5OR",
        "outputId": "7024a60a-2c7b-4570-9887-b0a8131e085c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptxas info    : 0 bytes gmem\n",
            "ptxas info    : Compiling entry function '_Z13GPU_laplace3dxxxPKfPf' for 'sm_70'\n",
            "ptxas info    : Function properties for _Z13GPU_laplace3dxxxPKfPf\n",
            "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
            "ptxas info    : Used 21 registers, 392 bytes cmem[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfyCekjazPh",
        "outputId": "e55d22db-7edd-4d8c-bb38-37c9b230dd53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 1008.8 (ms) \n",
            "\n",
            "Block dimensions: 32 x 2 x 8\n",
            "20x GPU_laplace3d_new: 877.4 (ms) \n",
            "\n",
            "Bandwidth Analysis:\n",
            "Time per iteration: 43.869 ms\n",
            "Data per iteration: 8.590 GB\n",
            "Effective Bandwidth: 195.81 GB/s\n",
            "\n",
            "Copy u2 to host: 2860.0 (ms) \n",
            "\n",
            "rms error = 0.066320 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Grid dimensions: 1024 x 1024 x 1024\n",
        "\n",
        "GPU Device 0: \"Turing\" with compute capability 7.5\n",
        "\n",
        "Copy u1 to device: 975.4 (ms)\n",
        "\n",
        "Block 2 x 2 x 2  ->  4028.775 ms\n",
        "Block 2 x 2 x 4  ->  3152.670 ms\n",
        "Block 2 x 2 x 8  ->  3131.752 ms\n",
        "Block 2 x 2 x 16  ->  3210.297 ms\n",
        "Block 2 x 2 x 24  ->  3272.550 ms\n",
        "Block 2 x 2 x 32  ->  3401.198 ms\n",
        "Block 2 x 2 x 64  ->  3515.413 ms\n",
        "Block 2 x 4 x 2  ->  3418.371 ms\n",
        "Block 2 x 4 x 4  ->  3346.674 ms\n",
        "Block 2 x 4 x 8  ->  3358.173 ms\n",
        "Block 2 x 4 x 16  ->  3472.517 ms\n",
        "Block 2 x 4 x 24  ->  3516.457 ms\n",
        "Block 2 x 4 x 32  ->  3552.722 ms\n",
        "Block 2 x 4 x 64  ->  3617.280 ms\n",
        "Block 2 x 8 x 2  ->  3561.329 ms\n",
        "Block 2 x 8 x 4  ->  3499.206 ms\n",
        "Block 2 x 8 x 8  ->  3572.329 ms\n",
        "Block 2 x 8 x 16  ->  3598.354 ms\n",
        "Block 2 x 8 x 24  ->  3623.103 ms\n",
        "Block 2 x 8 x 32  ->  3678.904 ms\n",
        "Block 2 x 8 x 64  ->  3999.664 ms\n",
        "Block 2 x 16 x 2  ->  3843.965 ms\n",
        "Block 2 x 16 x 4  ->  3857.678 ms\n",
        "Block 2 x 16 x 8  ->  3827.151 ms\n",
        "Block 2 x 16 x 16  ->  3827.921 ms\n",
        "Block 2 x 16 x 24  ->  3905.278 ms\n",
        "Block 2 x 16 x 32  ->  4019.314 ms\n",
        "Block 2 x 24 x 2  ->  3925.576 ms\n",
        "Block 2 x 24 x 4  ->  3861.359 ms\n",
        "Block 2 x 24 x 8  ->  3756.844 ms\n",
        "Block 2 x 24 x 16  ->  3815.725 ms\n",
        "Block 2 x 32 x 2  ->  3971.308 ms\n",
        "Block 2 x 32 x 4  ->  3797.692 ms\n",
        "Block 2 x 32 x 8  ->  3720.925 ms\n",
        "Block 2 x 32 x 16  ->  3882.498 ms\n",
        "Block 2 x 64 x 2  ->  3944.873 ms\n",
        "Block 2 x 64 x 4  ->  3827.793 ms\n",
        "Block 2 x 64 x 8  ->  3975.903 ms\n",
        "Block 4 x 2 x 2  ->  2564.700 ms\n",
        "Block 4 x 2 x 4  ->  2082.920 ms\n",
        "Block 4 x 2 x 8  ->  2344.964 ms\n",
        "Block 4 x 2 x 16  ->  2431.607 ms\n",
        "Block 4 x 2 x 24  ->  2427.282 ms\n",
        "Block 4 x 2 x 32  ->  2463.807 ms\n",
        "Block 4 x 2 x 64  ->  2559.384 ms\n",
        "Block 4 x 4 x 2  ->  2180.882 ms\n",
        "Block 4 x 4 x 4  ->  2439.271 ms\n",
        "Block 4 x 4 x 8  ->  2437.106 ms\n",
        "Block 4 x 4 x 16  ->  2417.604 ms\n",
        "Block 4 x 4 x 24  ->  2418.261 ms\n",
        "Block 4 x 4 x 32  ->  2469.730 ms\n",
        "Block 4 x 4 x 64  ->  2583.128 ms\n",
        "Block 4 x 8 x 2  ->  2514.749 ms\n",
        "Block 4 x 8 x 4  ->  2391.132 ms\n",
        "Block 4 x 8 x 8  ->  2301.352 ms\n",
        "Block 4 x 8 x 16  ->  2331.021 ms\n",
        "Block 4 x 8 x 24  ->  2490.983 ms\n",
        "Block 4 x 8 x 32  ->  2397.463 ms\n",
        "Block 4 x 16 x 2  ->  2560.818 ms\n",
        "Block 4 x 16 x 4  ->  2363.711 ms\n",
        "Block 4 x 16 x 8  ->  2346.293 ms\n",
        "Block 4 x 16 x 16  ->  2387.619 ms\n",
        "Block 4 x 24 x 2  ->  2544.709 ms\n",
        "Block 4 x 24 x 4  ->  2371.431 ms\n",
        "Block 4 x 24 x 8  ->  2456.529 ms\n",
        "Block 4 x 32 x 2  ->  2563.068 ms\n",
        "Block 4 x 32 x 4  ->  2425.422 ms\n",
        "Block 4 x 32 x 8  ->  2417.038 ms\n",
        "Block 4 x 64 x 2  ->  2679.237 ms\n",
        "Block 4 x 64 x 4  ->  2535.379 ms\n",
        "Block 8 x 2 x 2  ->  1446.926 ms\n",
        "Block 8 x 2 x 4  ->  1466.336 ms\n",
        "Block 8 x 2 x 8  ->  1447.469 ms\n",
        "Block 8 x 2 x 16  ->  1394.011 ms\n",
        "Block 8 x 2 x 24  ->  1424.741 ms\n",
        "Block 8 x 2 x 32  ->  1405.135 ms\n",
        "Block 8 x 2 x 64  ->  1591.388 ms\n",
        "Block 8 x 4 x 2  ->  1448.647 ms\n",
        "Block 8 x 4 x 4  ->  1391.279 ms\n",
        "Block 8 x 4 x 8  ->  1383.117 ms\n",
        "Block 8 x 4 x 16  ->  1387.184 ms\n",
        "Block 8 x 4 x 24  ->  1707.434 ms\n",
        "Block 8 x 4 x 32  ->  1621.762 ms\n",
        "Block 8 x 8 x 2  ->  1465.731 ms\n",
        "Block 8 x 8 x 4  ->  1393.674 ms\n",
        "Block 8 x 8 x 8  ->  1361.934 ms\n",
        "Block 8 x 8 x 16  ->  1571.893 ms\n",
        "Block 8 x 16 x 2  ->  1538.924 ms\n",
        "Block 8 x 16 x 4  ->  1421.554 ms\n",
        "Block 8 x 16 x 8  ->  1567.387 ms\n",
        "Block 8 x 24 x 2  ->  1561.719 ms\n",
        "Block 8 x 24 x 4  ->  1705.338 ms\n",
        "Block 8 x 32 x 2  ->  1599.737 ms\n",
        "Block 8 x 32 x 4  ->  1604.334 ms\n",
        "Block 8 x 64 x 2  ->  1726.994 ms\n",
        "Block 16 x 2 x 2  ->  1305.208 ms\n",
        "Block 16 x 2 x 4  ->  1230.835 ms\n",
        "Block 16 x 2 x 8  ->  1173.293 ms\n",
        "Block 16 x 2 x 16  ->  1152.732 ms\n",
        "Block 16 x 2 x 24  ->  1383.883 ms\n",
        "Block 16 x 2 x 32  ->  1264.628 ms\n",
        "Block 16 x 4 x 2  ->  1313.274 ms\n",
        "Block 16 x 4 x 4  ->  1203.122 ms\n",
        "Block 16 x 4 x 8  ->  1150.054 ms\n",
        "Block 16 x 4 x 16  ->  1269.721 ms\n",
        "Block 16 x 8 x 2  ->  1268.688 ms\n",
        "Block 16 x 8 x 4  ->  1182.125 ms\n",
        "Block 16 x 8 x 8  ->  1275.988 ms\n",
        "Block 16 x 16 x 2  ->  1265.813 ms\n",
        "Block 16 x 16 x 4  ->  1311.232 ms\n",
        "Block 16 x 24 x 2  ->  1469.645 ms\n",
        "Block 16 x 32 x 2  ->  1377.120 ms\n",
        "Block 24 x 2 x 2  ->  1350.105 ms\n",
        "Block 24 x 2 x 4  ->  1236.255 ms\n",
        "Block 24 x 2 x 8  ->  1187.500 ms\n",
        "Block 24 x 2 x 16  ->  1329.991 ms\n",
        "Block 24 x 4 x 2  ->  1310.304 ms\n",
        "Block 24 x 4 x 4  ->  1218.322 ms\n",
        "Block 24 x 4 x 8  ->  1337.341 ms\n",
        "Block 24 x 8 x 2  ->  1274.751 ms\n",
        "Block 24 x 8 x 4  ->  1364.607 ms\n",
        "Block 24 x 16 x 2  ->  1420.832 ms\n",
        "Block 32 x 2 x 2  ->  1186.519 ms\n",
        "Block 32 x 2 x 4  ->  1099.031 ms\n",
        "Block 32 x 2 x 8  ->  1036.686 ms\n",
        "Block 32 x 2 x 16  ->  1096.112 ms\n",
        "Block 32 x 4 x 2  ->  1154.237 ms\n",
        "Block 32 x 4 x 4  ->  1070.278 ms\n",
        "Block 32 x 4 x 8  ->  1109.132 ms\n",
        "Block 32 x 8 x 2  ->  1134.169 ms\n",
        "Block 32 x 8 x 4  ->  1150.491 ms\n",
        "Block 32 x 16 x 2  ->  1193.914 ms\n",
        "Block 64 x 2 x 2  ->  1163.561 ms\n",
        "Block 64 x 2 x 4  ->  1066.783 ms\n",
        "Block 64 x 2 x 8  ->  1079.992 ms\n",
        "Block 64 x 4 x 2  ->  1128.703 ms\n",
        "Block 64 x 4 x 4  ->  1103.254 ms\n",
        "Block 64 x 8 x 2  ->  1160.750 ms\n",
        "\n",
        "==== BEST CONFIGURATION ====\n",
        "Block: 32 x 2 x 8   Time: 1036.686 ms\n",
        "Copy u2 to host: 2831.6 (ms)\n",
        "\n",
        "rms error = 0.125000\n"
      ],
      "metadata": {
        "id": "HDFqrourHmJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "The next instructions check how many fp32 and integer instructions are performed by the two versions"
      ],
      "metadata": {
        "id": "8IUnwap2F64l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d\n",
        "!ncu --metrics \"smsp__sass_thread_inst_executed_op_fp32_pred_on.sum,smsp__sass_thread_inst_executed_op_integer_pred_on.sum\" ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kXdNtggGUv8",
        "outputId": "0127aa6c-e5f2-47c4-8ce2-24e214ec7cd7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 9820 (/content/laplace3d)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 958.5 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%....100% - 1 pass\n",
            "Block dimensions: 64 x 16 \n",
            "1x GPU_laplace3d: 1938.9 (ms) \n",
            "\n",
            "Copy u2 to host: 3281.5 (ms) \n",
            "\n",
            "rms error = 0.013208 \n",
            "==PROF== Disconnected from process 9820\n",
            "[9820] laplace3d@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (16, 64, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 17,849,978,832\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n",
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 9975 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 1065.7 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%....50%\n",
            "==WARNING== Launching the workload is taking more time than expected. If this continues to hang, terminate the profile and re-try by profiling the range of all related launches using '--replay-mode range'. See https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#replay for more details.\n",
            "....100% - 1 pass\n",
            "Block dimensions: 32 x 2 x 8\n",
            "1x GPU_laplace3d_new: 4094.6 (ms) \n",
            "\n",
            "Bandwidth Analysis:\n",
            "Time per iteration: 4094.609 ms\n",
            "Data per iteration: 8.590 GB\n",
            "Effective Bandwidth: 2.10 GB/s\n",
            "\n",
            "Copy u2 to host: 3288.3 (ms) \n",
            "\n",
            "rms error = 0.013208 \n",
            "==PROF== Disconnected from process 9975\n",
            "[9975] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 128)x(32, 2, 8), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: Command line profiler metrics\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    Metric Name                                            Metric Unit   Metric Value\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "    smsp__sass_thread_inst_executed_op_fp32_pred_on.sum           inst  6,404,775,888\n",
            "    smsp__sass_thread_inst_executed_op_integer_pred_on.sum        inst 66,471,526,272\n",
            "    ------------------------------------------------------ ----------- --------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VUuh0SdITB-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu ./laplace3d\n",
        "!ncu ./laplace3d_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef846ef8-b194-4e9e-dce6-f207c8361f23",
        "id": "1USbXCV4TCpc",
        "collapsed": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 10242 (/content/laplace3d)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 969.2 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%\n",
            "==WARNING== Backing up device memory in system memory. Kernel replay might be slow. Consider using \"--replay-mode application\" to avoid memory save-and-restore.\n",
            "....50%....100% - 9 passes\n",
            "Block dimensions: 64 x 16 \n",
            "1x GPU_laplace3d: 3066.6 (ms) \n",
            "\n",
            "Copy u2 to host: 3519.4 (ms) \n",
            "\n",
            "rms error = 0.013208 \n",
            "==PROF== Disconnected from process 10242\n",
            "[10242] laplace3d@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (16, 64, 1)x(64, 16, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    35,427,353\n",
            "    Memory Throughput                 %         79.95\n",
            "    DRAM Throughput                   %         79.95\n",
            "    Duration                         ms         60.56\n",
            "    L1/TEX Cache Throughput           %         47.64\n",
            "    L2 Cache Throughput               %         19.45\n",
            "    SM Active Cycles              cycle 35,167,961.88\n",
            "    Compute (SM) Throughput           %         36.82\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   Memory is more heavily utilized than Compute: Look at the Memory Workload Analysis section to identify the    \n",
            "          DRAM bottleneck. Check memory replay (coalescing) metrics to make sure you're efficiently utilizing the       \n",
            "          bytes transferred. Also consider whether it is possible to do more work per memory access (kernel fusion) or  \n",
            "          whether there are values you can (re)compute.                                                                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                 1,024\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                  1,024\n",
            "    Registers Per Thread             register/thread              64\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread       1,048,576\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                               25.60\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            1\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            1\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        99.42\n",
            "    Achieved Active Warps Per SM           warp        31.81\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- --------------\n",
            "    Metric Name                Metric Unit   Metric Value\n",
            "    -------------------------- ----------- --------------\n",
            "    Average DRAM Active Cycles       cycle 241,545,880.50\n",
            "    Total DRAM Elapsed Cycles        cycle  2,416,908,288\n",
            "    Average L1 Active Cycles         cycle  35,167,961.88\n",
            "    Total L1 Elapsed Cycles          cycle  1,415,894,496\n",
            "    Average L2 Active Cycles         cycle  52,037,725.44\n",
            "    Total L2 Elapsed Cycles          cycle  1,656,909,312\n",
            "    Average SM Active Cycles         cycle  35,167,961.88\n",
            "    Total SM Elapsed Cycles          cycle  1,415,894,496\n",
            "    Average SMSP Active Cycles       cycle  35,021,132.28\n",
            "    Total SMSP Elapsed Cycles        cycle  5,663,577,984\n",
            "    -------------------------- ----------- --------------\n",
            "\n",
            "Grid dimensions: 1024 x 1024 x 1024 \n",
            "\n",
            "==PROF== Connected to process 10409 (/content/laplace3d_new)\n",
            "GPU Device 0: \"Turing\" with compute capability 7.5\n",
            "\n",
            "Copy u1 to device: 995.2 (ms) \n",
            "\n",
            "==PROF== Profiling \"GPU_laplace3d\" - 0: 0%\n",
            "==WARNING== Backing up device memory in system memory. Kernel replay might be slow. Consider using \"--replay-mode application\" to avoid memory save-and-restore.\n",
            "....50%....100% - 9 passes\n",
            "Block dimensions: 32 x 2 x 8\n",
            "1x GPU_laplace3d_new: 3419.9 (ms) \n",
            "\n",
            "Bandwidth Analysis:\n",
            "Time per iteration: 3419.857 ms\n",
            "Data per iteration: 8.590 GB\n",
            "Effective Bandwidth: 2.51 GB/s\n",
            "\n",
            "Copy u2 to host: 3260.3 (ms) \n",
            "\n",
            "rms error = 0.013208 \n",
            "==PROF== Disconnected from process 10409\n",
            "[10409] laplace3d_new@127.0.0.1\n",
            "  GPU_laplace3d(long long, long long, long long, const float *, float *) (32, 512, 128)x(32, 2, 8), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ----------- -------------\n",
            "    Metric Name             Metric Unit  Metric Value\n",
            "    ----------------------- ----------- -------------\n",
            "    DRAM Frequency                  Ghz          4.99\n",
            "    SM Frequency                    Mhz        585.00\n",
            "    Elapsed Cycles                cycle    37,126,313\n",
            "    Memory Throughput                 %         57.25\n",
            "    DRAM Throughput                   %         57.25\n",
            "    Duration                         ms         63.46\n",
            "    L1/TEX Cache Throughput           %         52.17\n",
            "    L2 Cache Throughput               %         28.66\n",
            "    SM Active Cycles              cycle 37,124,986.83\n",
            "    Compute (SM) Throughput           %         50.30\n",
            "    ----------------------- ----------- -------------\n",
            "\n",
            "    OPT   This kernel exhibits low compute throughput and memory bandwidth utilization relative to the peak performance \n",
            "          of this device. Achieved compute throughput and/or memory bandwidth below 60.0% of peak typically indicate    \n",
            "          latency issues. Look at Scheduler Statistics and Warp State Statistics for potential reasons.                 \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                   512\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                              2,097,152\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block        byte/block               0\n",
            "    # SMs                                         SM              40\n",
            "    Threads                                   thread   1,073,741,824\n",
            "    Uses Green Context                                             0\n",
            "    Waves Per SM                                           26,214.40\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            5\n",
            "    Block Limit Shared Mem                block           16\n",
            "    Block Limit Warps                     block            2\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        84.03\n",
            "    Achieved Active Warps Per SM           warp        26.89\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    OPT   Est. Local Speedup: 15.97%                                                                                    \n",
            "          The difference between calculated theoretical (100.0%) and measured achieved occupancy (84.0%) can be the     \n",
            "          result of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can   \n",
            "          occur between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices   \n",
            "          Guide (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on     \n",
            "          optimizing occupancy.                                                                                         \n",
            "\n",
            "    Section: GPU and Memory Workload Distribution\n",
            "    -------------------------- ----------- -------------\n",
            "    Metric Name                Metric Unit  Metric Value\n",
            "    -------------------------- ----------- -------------\n",
            "    Average DRAM Active Cycles       cycle   181,464,224\n",
            "    Total DRAM Elapsed Cycles        cycle 2,535,965,696\n",
            "    Average L1 Active Cycles         cycle 37,124,986.83\n",
            "    Total L1 Elapsed Cycles          cycle 1,484,627,600\n",
            "    Average L2 Active Cycles         cycle 53,802,644.47\n",
            "    Total L2 Elapsed Cycles          cycle 1,736,368,416\n",
            "    Average SM Active Cycles         cycle 37,124,986.83\n",
            "    Total SM Elapsed Cycles          cycle 1,484,627,600\n",
            "    Average SMSP Active Cycles       cycle 37,116,059.21\n",
            "    Total SMSP Elapsed Cycles        cycle 5,938,510,400\n",
            "    -------------------------- ----------- -------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "MtAImDxLjEpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d.cu\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "                              const float* __restrict__ d_u1,\n",
        "                                    float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  j    = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "  indg = i + j*NX;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  if ( i>=0 && i<=NX-1 && j>=0 && j<=NY-1 ) {\n",
        "\n",
        "    for (k=0; k<NZ; k++) {\n",
        "\n",
        "      if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) { // bound elements\n",
        "        u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "      }\n",
        "      else {\n",
        "        u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "             + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "             + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "      }\n",
        "      d_u2[indg] = u2;\n",
        "\n",
        "      indg += KOFF;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, REPEAT=20,\n",
        "          i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "         *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "//   cudaEventRecord(start);\n",
        "//   for (i=0; i<REPEAT; i++) {\n",
        "//     Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "//     h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "//   }\n",
        "\n",
        "//   cudaEventRecord(stop);\n",
        "//   cudaEventSynchronize(stop);\n",
        "//   cudaEventElapsedTime(&milli, start, stop);\n",
        "//   printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  int block_sizes[] = {2, 4, 8, 16, 24, 32, 64};   // try common warp-friendly sizes\n",
        "  int nSizes = sizeof(block_sizes)/sizeof(block_sizes[0]);\n",
        "\n",
        "  float bestTime = 1e30;\n",
        "  int bestBX = 0, bestBY = 0;\n",
        "\n",
        "  for (int ix = 0; ix < nSizes; ix++) {\n",
        "  for (int iy = 0; iy < nSizes; iy++) {\n",
        "\n",
        "    int BLOCK_X = block_sizes[ix];\n",
        "    int BLOCK_Y = block_sizes[iy];\n",
        "\n",
        "    // Skip illegal configurations (>1024 threads per block)\n",
        "    if (BLOCK_X * BLOCK_Y > 1024) continue;\n",
        "\n",
        "    int bx = 1 + (NX-1)/BLOCK_X;\n",
        "    int by = 1 + (NY-1)/BLOCK_Y;\n",
        "\n",
        "    dim3 dimGrid(bx, by);\n",
        "    dim3 dimBlock(BLOCK_X, BLOCK_Y);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    for (i = 0; i < REPEAT; i++) {\n",
        "    GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "    getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "    d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "    printf(\"Block %2d x %2d  ->  %.3f ms\\n\", BLOCK_X, BLOCK_Y, milli);\n",
        "\n",
        "    if (milli < bestTime) {\n",
        "    bestTime = milli;\n",
        "    bestBX = BLOCK_X;\n",
        "    bestBY = BLOCK_Y;\n",
        "    }\n",
        "  }\n",
        "  }\n",
        "\n",
        "printf(\"\\n==== BEST CONFIGURATION ====\\n\");\n",
        "printf(\"Block: %d x %d   Time: %.3f ms\\n\", bestBX, bestBY, bestTime);\n",
        "\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcwQANS22i3Q",
        "outputId": "8ea7aa79-6947-4a67-93ee-f47dd20ae457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting laplace3d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile laplace3d_new.cu\n",
        "\n",
        "\n",
        "//\n",
        "// Program to solve Laplace equation on a regular 3D grid\n",
        "//\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// kernel function\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "__global__ void GPU_laplace3d(long long NX, long long NY, long long NZ,\n",
        "\t         \t      const float* __restrict__ d_u1,\n",
        "\t\t\t            float* __restrict__ d_u2)\n",
        "{\n",
        "  long long i, j, k, indg, IOFF, JOFF, KOFF;\n",
        "  float     u2, sixth=1.0f/6.0f;\n",
        "\n",
        "  //\n",
        "  // define global indices and array offsets\n",
        "  //\n",
        "\n",
        "  i    = threadIdx.x + blockIdx.x*blockDim.x;\n",
        "  j    = threadIdx.y + blockIdx.y*blockDim.y;\n",
        "  k    = threadIdx.z + blockIdx.z*blockDim.z;\n",
        "\n",
        "  IOFF = 1;\n",
        "  JOFF = NX;\n",
        "  KOFF = NX*NY;\n",
        "\n",
        "  indg = i + j*JOFF + k*KOFF;\n",
        "\n",
        "  if (i>=0 && i<=NX-1 && j>=0 && j<=NY-1 && k>=0 && k<=NZ-1) {\n",
        "    if (i==0 || i==NX-1 || j==0 || j==NY-1 || k==0 || k==NZ-1) {\n",
        "      u2 = d_u1[indg];  // Dirichlet b.c.'s\n",
        "    }\n",
        "    else {\n",
        "      u2 = ( d_u1[indg-IOFF] + d_u1[indg+IOFF]\n",
        "           + d_u1[indg-JOFF] + d_u1[indg+JOFF]\n",
        "           + d_u1[indg-KOFF] + d_u1[indg+KOFF] ) * sixth;\n",
        "    }\n",
        "    d_u2[indg] = u2;\n",
        "  }\n",
        "}\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Gold routine -- reference C++ code\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "void Gold_laplace3d(long long NX, long long NY, long long NZ, float* u1, float* u2)\n",
        "{\n",
        "  long long i, j, k, ind;\n",
        "  float     sixth=1.0f/6.0f;  // predefining this improves performance more than 10%\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {   // i loop innermost for sequential memory access\n",
        "\t      ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1) {\n",
        "          u2[ind] = u1[ind];          // Dirichlet b.c.'s\n",
        "        }\n",
        "        else {\n",
        "          u2[ind] = ( u1[ind-1    ] + u1[ind+1    ]\n",
        "                    + u1[ind-NX   ] + u1[ind+NX   ]\n",
        "                    + u1[ind-NX*NY] + u1[ind+NX*NY] ) * sixth;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "// Main program\n",
        "////////////////////////////////////////////////////////////////////////\n",
        "\n",
        "int main(int argc, const char **argv){\n",
        "\n",
        "  int       NX=1024, NY=1024, NZ=1024, REPEAT=20,\n",
        "            BLOCK_X, BLOCK_Y, BLOCK_Z,bx, by, bz, i, j, k;\n",
        "  float    *h_u1, *h_u2,\n",
        "           *d_u1, *d_u2, *d_foo;\n",
        "\n",
        "  size_t    ind, bytes = sizeof(float) * NX*NY*NZ;\n",
        "\n",
        "  printf(\"Grid dimensions: %d x %d x %d \\n\\n\", NX, NY, NZ);\n",
        "\n",
        "  // initialise card\n",
        "\n",
        "  findCudaDevice(argc, argv);\n",
        "\n",
        "  // initialise CUDA timing\n",
        "\n",
        "  float milli;\n",
        "  cudaEvent_t start, stop;\n",
        "  cudaEventCreate(&start);\n",
        "  cudaEventCreate(&stop);\n",
        "\n",
        "  // allocate memory for arrays\n",
        "\n",
        "  h_u1 = (float *)malloc(bytes);\n",
        "  h_u2 = (float *)malloc(bytes);\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u1, bytes) );\n",
        "  checkCudaErrors( cudaMalloc((void **)&d_u2, bytes) );\n",
        "\n",
        "  // initialise u1\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "\n",
        "        if (i==0 || i==NX-1 || j==0 || j==NY-1|| k==0 || k==NZ-1)\n",
        "          h_u1[ind] = 1.0f;           // Dirichlet b.c.'s\n",
        "        else\n",
        "          h_u1[ind] = 0.0f;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  // copy u1 to device\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(d_u1, h_u1, bytes,\n",
        "                              cudaMemcpyHostToDevice) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u1 to device: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // Gold treatment\n",
        "\n",
        "//   cudaEventRecord(start);\n",
        "//   for (i=0; i<REPEAT; i++) {\n",
        "//     Gold_laplace3d(NX, NY, NZ, h_u1, h_u2);\n",
        "//     h_foo = h_u1; h_u1 = h_u2; h_u2 = h_foo;   // swap h_u1 and h_u2\n",
        "//   }\n",
        "\n",
        "//   cudaEventRecord(stop);\n",
        "//   cudaEventSynchronize(stop);\n",
        "//   cudaEventElapsedTime(&milli, start, stop);\n",
        "//   printf(\"%dx Gold_laplace3d: %.1f (ms) \\n\\n\", REPEAT, milli);\n",
        "\n",
        "  // Set up the execution configuration\n",
        "\n",
        "  int block_sizes[] = {2, 4, 8, 16, 24, 32, 64};\n",
        "  int nSizes = sizeof(block_sizes)/sizeof(block_sizes[0]);\n",
        "\n",
        "  float bestTime = 1e30;\n",
        "  int bestBX = 0, bestBY = 0, bestBZ = 0;\n",
        "\n",
        "  for (int ix = 0; ix < nSizes; ix++) {\n",
        "    for (int iy = 0; iy < nSizes; iy++) {\n",
        "      for (int iz = 0; iz < nSizes; iz++) {\n",
        "\n",
        "        BLOCK_X = block_sizes[ix];\n",
        "        BLOCK_Y = block_sizes[iy];\n",
        "        BLOCK_Z = block_sizes[iz];\n",
        "\n",
        "        if (BLOCK_X * BLOCK_Y * BLOCK_Z > 1024) continue;\n",
        "\n",
        "        bx = 1 + (NX-1)/BLOCK_X;\n",
        "        by = 1 + (NY-1)/BLOCK_Y;\n",
        "        bz = 1 + (NZ-1)/BLOCK_Z;\n",
        "\n",
        "        dim3 dimGrid(bx, by, bz);\n",
        "        dim3 dimBlock(BLOCK_X, BLOCK_Y, BLOCK_Z);\n",
        "\n",
        "        cudaDeviceSynchronize();\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        for (i=0; i<REPEAT; i++) {\n",
        "          GPU_laplace3d<<<dimGrid, dimBlock>>>(NX, NY, NZ, d_u1, d_u2);\n",
        "          getLastCudaError(\"GPU_laplace3d execution failed\\n\");\n",
        "\n",
        "          d_foo = d_u1; d_u1 = d_u2; d_u2 = d_foo;\n",
        "        }\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "        cudaEventElapsedTime(&milli, start, stop);\n",
        "\n",
        "        printf(\"Block %d x %d x %d  ->  %.3f ms\\n\", BLOCK_X, BLOCK_Y, BLOCK_Z, milli);\n",
        "\n",
        "        if (milli < bestTime) {\n",
        "          bestTime = milli;\n",
        "          bestBX = BLOCK_X; bestBY = BLOCK_Y; bestBZ = BLOCK_Z;\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"\\n==== BEST CONFIGURATION ====\\n\");\n",
        "  printf(\"Block: %d x %d x %d   Time: %.3f ms\\n\", bestBX, bestBY, bestBZ, bestTime);\n",
        "\n",
        "  // Read back GPU results\n",
        "\n",
        "  cudaEventRecord(start);\n",
        "  checkCudaErrors( cudaMemcpy(h_u2, d_u1, bytes, cudaMemcpyDeviceToHost) );\n",
        "  cudaEventRecord(stop);\n",
        "  cudaEventSynchronize(stop);\n",
        "  cudaEventElapsedTime(&milli, start, stop);\n",
        "  printf(\"Copy u2 to host: %.1f (ms) \\n\\n\", milli);\n",
        "\n",
        "  // error check\n",
        "\n",
        "  float err = 0.0;\n",
        "\n",
        "  for (k=0; k<NZ; k++) {\n",
        "    for (j=0; j<NY; j++) {\n",
        "      for (i=0; i<NX; i++) {\n",
        "        ind = i + j*NX + k*NX*NY;\n",
        "        err += (h_u1[ind]-h_u2[ind])*(h_u1[ind]-h_u2[ind]);\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  printf(\"rms error = %f \\n\",sqrt(err/ (float)(NX*NY*NZ)));\n",
        "\n",
        " // Release GPU and CPU memory\n",
        "\n",
        "  checkCudaErrors( cudaFree(d_u1) );\n",
        "  checkCudaErrors( cudaFree(d_u2) );\n",
        "  free(h_u1);\n",
        "  free(h_u2);\n",
        "\n",
        "  cudaDeviceReset();\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8xscLewbPlF",
        "outputId": "9ebad7b2-db3f-4208-a164-f03a84d1ddad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing laplace3d_new.cu\n"
          ]
        }
      ]
    }
  ]
}